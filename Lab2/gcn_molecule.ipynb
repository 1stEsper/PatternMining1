{
  "cells": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (2.8.1.dev20241211194225)\n",
      "Requirement already satisfied: sympy in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from deepchem) (1.12)\n",
      "Requirement already satisfied: joblib in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from deepchem) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.10.1 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from deepchem) (1.10.1)\n",
      "Requirement already satisfied: rdkit in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from deepchem) (2024.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from deepchem) (1.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from pandas->deepchem) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from pandas->deepchem) (2.8.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from rdkit->deepchem) (10.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from scikit-learn->deepchem) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from sympy->deepchem) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --pre deepchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dgllife in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: networkx>=2.1 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (2.8.8)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (1.10.1)\n",
      "Requirement already satisfied: hyperopt in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (0.2.7)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (1.23.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (1.3.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from dgllife) (4.66.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from requests>=2.22.0->dgllife) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from requests>=2.22.0->dgllife) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from requests>=2.22.0->dgllife) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from scikit-learn>=0.22.2->dgllife) (3.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from hyperopt->dgllife) (1.16.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from hyperopt->dgllife) (0.10.9.7)\n",
      "Requirement already satisfied: future in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from hyperopt->dgllife) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from hyperopt->dgllife) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from pandas->dgllife) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from pandas->dgllife) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\maiyp\\anaconda3\\envs\\crosswalk\\lib\\site-packages (from tqdm->dgllife) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install dgllife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (c:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (c:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepchem.models import GCNModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import iris dataset\n",
    "df = pd.read_csv('data/iris.csv', header=None)\n",
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "species_map = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "df['species'] = df['species'].map(species_map)\n",
    "\n",
    "#standardize features\n",
    "scaler = StandardScaler()\n",
    "features = df.iloc[:, :-1].values\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "labels = df['species'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data with indices\n",
    "indices = np.arange(len(features_scaled))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "#split features and labels\n",
    "train_features = features_scaled[train_idx]\n",
    "test_features = features_scaled[test_idx]\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]\n",
    "\n",
    "# Cell 4: Create graph structures\n",
    "def create_graph(features):\n",
    "    n_samples = len(features)\n",
    "    k = 5  #nb neighbors\n",
    "    edge_index = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        distances = []\n",
    "        for j in range(n_samples):\n",
    "            if i != j:\n",
    "                dist = np.linalg.norm(features[i] - features[j])\n",
    "                distances.append((j, dist))\n",
    "        \n",
    "        nearest_neighbors = sorted(distances, key=lambda x: x[1])[:k]\n",
    "        for neighbor, _ in nearest_neighbors:\n",
    "            edge_index.append([i, neighbor])\n",
    "            edge_index.append([neighbor, i])\n",
    "    \n",
    "    edge_index = np.array(edge_index, dtype=np.int32).T\n",
    "    return dc.feat.graph_data.GraphData(\n",
    "        node_features=features.astype(np.float32),\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=n_samples,\n",
    "        num_edges=len(edge_index)\n",
    "    )\n",
    "\n",
    "#separation train and test\n",
    "train_graph = create_graph(train_features)\n",
    "test_graph = create_graph(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create deepchem datasets train/test\n",
    "train_dataset = dc.data.NumpyDataset([train_graph], train_labels.reshape(-1, 1))\n",
    "test_dataset = dc.data.NumpyDataset([test_graph], test_labels.reshape(-1, 1))\n",
    "\n",
    "n_features = features_scaled.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "[16:01:39] C:\\Users\\Administrator\\dgl-0.5\\src\\runtime\\c_runtime_api.cc:88: Check failed: allow_missing: Device API gpu is not enabled. Please install the cuda version of dgl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GCNModel(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m, n_tasks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      2\u001b[0m                  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, number_atom_features\u001b[38;5;241m=\u001b[39mn_features)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\deepchem\\models\\torch_models\\torch_model.py:338\u001b[0m, in \u001b[0;36mTorchModel.fit\u001b[1;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    290\u001b[0m         dataset: Dataset,\n\u001b[0;32m    291\u001b[0m         nb_epoch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m         callbacks: Union[Callable, List[Callable]] \u001b[38;5;241m=\u001b[39m [],\n\u001b[0;32m    299\u001b[0m         all_losses: Optional[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m    300\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train this model on a dataset.\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    The average loss over the most recent checkpoint interval\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_checkpoints_to_keep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\deepchem\\models\\torch_models\\torch_model.py:428\u001b[0m, in \u001b[0;36mTorchModel.fit_generator\u001b[1;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[0;32m    426\u001b[0m     restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    427\u001b[0m inputs: OneOrMany[torch\u001b[38;5;241m.\u001b[39mTensor]\n\u001b[1;32m--> 428\u001b[0m inputs, labels, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Execute the loss function, accumulating the gradients.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\deepchem\\models\\torch_models\\gcn.py:355\u001b[0m, in \u001b[0;36mGCNModel._prepare_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    351\u001b[0m inputs, labels, weights \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m    352\u001b[0m dgl_graphs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    353\u001b[0m     graph\u001b[38;5;241m.\u001b[39mto_dgl_graph(self_loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_loop) \u001b[38;5;28;01mfor\u001b[39;00m graph \u001b[38;5;129;01min\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    354\u001b[0m ]\n\u001b[1;32m--> 355\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mdgl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdgl_graphs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m _, labels, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(GCNModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_prepare_batch(\n\u001b[0;32m    357\u001b[0m     ([], labels, weights))\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, labels, weights\n",
      "File \u001b[1;32mc:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\dgl\\heterograph.py:5448\u001b[0m, in \u001b[0;36mDGLHeteroGraph.to\u001b[1;34m(self, device, **kwargs)\u001b[0m\n\u001b[0;32m   5445\u001b[0m ret \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   5447\u001b[0m \u001b[38;5;66;03m# 1. Copy graph structure\u001b[39;00m\n\u001b[1;32m-> 5448\u001b[0m ret\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dgl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5450\u001b[0m \u001b[38;5;66;03m# 2. Copy features\u001b[39;00m\n\u001b[0;32m   5451\u001b[0m \u001b[38;5;66;03m# TODO(minjie): handle initializer\u001b[39;00m\n\u001b[0;32m   5452\u001b[0m new_nframes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\dgl\\heterograph_index.py:237\u001b[0m, in \u001b[0;36mHeteroGraphIndex.copy_to\u001b[1;34m(self, ctx)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy_to\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Copy this immutable graph index to the given device context.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    NOTE: this method only works for immutable graph index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m        The graph index on the given device context.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CAPI_DGLHeteroCopyTo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py:188\u001b[0m, in \u001b[0;36mFunctionBase.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m DGLValue()\n\u001b[0;32m    187\u001b[0m ret_tcode \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[1;32m--> 188\u001b[0m \u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDGLFuncCall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_tcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m _ \u001b[38;5;241m=\u001b[39m temp_args\n\u001b[0;32m    192\u001b[0m _ \u001b[38;5;241m=\u001b[39m args\n",
      "File \u001b[1;32mc:\\Users\\MAIYP\\anaconda3\\envs\\crosswalk\\lib\\site-packages\\dgl\\_ffi\\base.py:65\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(py_str(_LIB\u001b[38;5;241m.\u001b[39mDGLGetLastError()))\n",
      "\u001b[1;31mDGLError\u001b[0m: [16:01:39] C:\\Users\\Administrator\\dgl-0.5\\src\\runtime\\c_runtime_api.cc:88: Check failed: allow_missing: Device API gpu is not enabled. Please install the cuda version of dgl."
     ]
    }
   ],
   "source": [
    "model = GCNModel(mode='classification', n_tasks=1,\n",
    "                 batch_size=16, learning_rate=0.001, number_atom_features=n_features)\n",
    "\n",
    "#train model\n",
    "model.fit(train_dataset, nb_epoch=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosswalk",
   "language": "python",
   "name": "python3"
=======
      "cell_type": "markdown",
      "metadata": {
        "id": "XXFwRc_u2Gpl"
      },
      "source": [
        "Homework 2: Graph Neural Network for chemistry\n",
        "\n",
        "2) Graph neural networks for molecules (GCN)\n",
        "- experiment GCN from the deepchem python library\n",
        "- understand the GCN structure and learning (see GNN course slides)\n",
        "- test it on several supervised datasets, in order the make node classification or graph classification\n",
        "- evaluate (explain the measures) and discuss the results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU0LzPurAwjf",
        "outputId": "c0baf592-6bc5-4854-dac3-e181c2520c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/home/leon/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: deepchem in /home/leon/anaconda3/lib/python3.11/site-packages (2.8.1.dev20241213202457)\n",
            "Requirement already satisfied: joblib in /home/leon/anaconda3/lib/python3.11/site-packages (from deepchem) (1.3.2)\n",
            "Requirement already satisfied: numpy<2 in /home/leon/anaconda3/lib/python3.11/site-packages (from deepchem) (1.24.3)\n",
            "Requirement already satisfied: pandas in /home/leon/anaconda3/lib/python3.11/site-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /home/leon/anaconda3/lib/python3.11/site-packages (from deepchem) (1.5.2)\n",
            "Requirement already satisfied: sympy in /home/leon/anaconda3/lib/python3.11/site-packages (from deepchem) (1.13.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /home/leon/anaconda3/lib/python3.11/site-packages (from deepchem) (1.14.1)\n",
            "Requirement already satisfied: rdkit in /home/leon/anaconda3/lib/python3.11/site-packages (from deepchem) (2024.3.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/leon/anaconda3/lib/python3.11/site-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/leon/anaconda3/lib/python3.11/site-packages (from pandas->deepchem) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/leon/anaconda3/lib/python3.11/site-packages (from pandas->deepchem) (2023.4)\n",
            "Requirement already satisfied: Pillow in /home/leon/anaconda3/lib/python3.11/site-packages (from rdkit->deepchem) (9.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/leon/anaconda3/lib/python3.11/site-packages (from scikit-learn->deepchem) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/leon/anaconda3/lib/python3.11/site-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/leon/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/home/leon/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/home/leon/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/home/leon/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/home/leon/anaconda3/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --pre deepchem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdmftJ-gAwji"
      },
      "source": [
        "We make a first test the DeepChem library with the code mentioned in the tutorial. We load the Tox21 dataset with the featurizer 'GraphConv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyWrDpbtAwjj",
        "outputId": "bcb655db-d7ce-422d-a495-99e88674d129"
      },
      "outputs": [],
      "source": [
        "import deepchem as dc\n",
        "\n",
        "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsNO01cIAwjk"
      },
      "source": [
        "Train the graph convolutional network for classification with GraphConvModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Q6Wb_4mhAwjk",
        "outputId": "a13e6d1a-9f08-4418-ccb2-7e64c97e6dbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.30834794998168946"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_tasks = len(tasks)\n",
        "model = dc.models.GraphConvModel(n_tasks, mode='classification', batch_normalize=False)\n",
        "model.fit(train_dataset, nb_epoch=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JollkxTYAwjl"
      },
      "source": [
        "Evaluate the performance of the model. We use the metric ROC-AUC score (tradeoff between precision and recall)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TsQ02WoHAwjl",
        "outputId": "caf3278d-fa68-4445-a734-317abc969f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set score: {'roc_auc_score': 0.9662236418729662}\n",
            "Test set score: {'roc_auc_score': 0.7141046267308472}\n"
          ]
        }
      ],
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
        "print('Training set score:', model.evaluate(train_dataset, [metric], transformers))\n",
        "print('Test set score:', model.evaluate(test_dataset, [metric], transformers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am9wSsEsCYiD"
      },
      "source": [
        "Let's use the SIRTUIN6 Small Molecules dataset, for classification, which includes 100 molecules with descriptors to determine the candidate inhibitors of a target protein. The molecules are grouped based on low- and high-BFE which we use for the classification.\n",
        "Link to the dataset:\n",
        "https://archive.ics.uci.edu/dataset/748/sirtuin6+small+molecules-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "taWgTaQ-CtRG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Efn3yxMYCSD_"
      },
      "outputs": [],
      "source": [
        "#import sirtuin6 dataset\n",
        "df = pd.read_csv('data/SIRTUIN6.csv')\n",
        "X = df.drop('Class', axis=1).values\n",
        "y = (df['Class'] == 'High_BFE').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JUtx6zALCyFU"
      },
      "outputs": [],
      "source": [
        "#split data between train, test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "y_train = np.expand_dims(y_train, axis=1)\n",
        "y_test = np.expand_dims(y_test, axis=1)\n",
        "\n",
        "train_dataset = dc.data.NumpyDataset(X_train_scaled, y_train)\n",
        "test_dataset = dc.data.NumpyDataset(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXDyDCxbCz9q",
        "outputId": "966bb2c2-ca9d-4f78-a116-f27766ab63e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6707041931152343"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_features = X_train.shape[1]\n",
        "model = dc.models.MultitaskClassifier(n_tasks=1, n_features=n_features, layer_sizes=[64, 32], dropout=0.2)\n",
        "\n",
        "#train the model\n",
        "model.fit(train_dataset, nb_epoch=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tZwMeltDJnUO"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = model.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qMtfA17QhNwb"
      },
      "outputs": [],
      "source": [
        "#we convert the probabilities to class predictions to solve issues with shape\n",
        "y_pred_classes = np.argmax(y_pred_proba, axis=2)\n",
        "y_pred_classes = y_pred_classes.flatten()\n",
        "y_test_flat = y_test.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtEv_f_clorP"
      },
      "source": [
        "We perform evaluation on the regular measures for models with the function classification_report from sklearn.metrics. It covers precision, recall, f1-score and support for the classes.  \n",
        "- Precision : measures the accuracy of positive predictions.\n",
        "- Recall : measures the ability of the model to find all positive samples.\n",
        "- f1-score : mean of precision and recall.\n",
        "- suport : number of true samples in each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rCew0l9K8rl",
        "outputId": "c9af2dab-4c07-4741-e118-d04bd3505640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.88      0.78         8\n",
            "           1       0.90      0.75      0.82        12\n",
            "\n",
            "    accuracy                           0.80        20\n",
            "   macro avg       0.80      0.81      0.80        20\n",
            "weighted avg       0.82      0.80      0.80        20\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test_flat, y_pred_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR6yLvhYqVbq"
      },
      "source": [
        "We can also print the confusion matrix which compares the predicted labels with the true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "-iKdVxwuhcaH",
        "outputId": "31ed5b1a-0bf9-4e03-cbf9-a908270c2903"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_flat, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
>>>>>>> fa93053c1361cbf6bb882840398432af769d5100
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
